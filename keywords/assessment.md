---
title: Digital Pedagogy in the Humanities
subtitle: Concepts, Models, and Experiments
chapter: Assessment
URL: keywords/assessment.md
author: 
- family: Clark
  given: J. Elizabeth 
editor: 
- family: Sayers
  given: Jentery
publisher: Modern Language Association
type: book
---

# ASSESSMENT (Draft)
 
### J. Elizabeth Clark
LaGuardia Community College, CUNY

---

##### Publication Status:
* unreviewed draft
* **draft version undergoing editorial review**
* draft version undergoing peer-to-peer review
* published 

--- 

## CURATORIAL STATEMENT

I recently showed the Michael Radform version of *1984* to students in my utopian fiction course. They were immediately struck by the surveillance in Oceania, remarking on the ways Big Brother perpetually watches. Of course, they were able to draw easy parallels to the world of Oceania and the rise of a surveillance culture in contemporary life afforded by our indiscriminate use of technology. Big Brother is a useful starting point for thinking about assessment and digital pedagogy because it is exactly what everyone fears. Assessment is often seen as an external classroom practice, something done *to* faculty and students rather than by them. The word, "assessment," conjures up myriad negative connotations about campus accreditation visits, the use of big data and metrics by administrations as a weapon against faculty, and the disconnect between classroom practices and assessment measures.

When I think about technology and education, David Eggers's *The Circle* describes the ultimate educational dystopia. On a tour of the fictional techno giant, The Circle, protagonist Mae Holland shows her viewers a vision of the future of education: "We're inches away from the moment when, by the time a student is ready for college, we have complete knowledge of everything that student has learned. Every word they read, every word they looked up, every sentence they highlighted, ever equation they wrote, ever answer and correction. The guesswork of knowing where all students stand and what they know will be over" (231). Although we have not yet arrived at that point, technology increasingly makes tracking convenient, easy, and transparent. But to what end? Few of us need a primer on the way in which metrics can go awry. One need only look at the classrooms of K-12 teachers under the yoke of No Child Left Behind legislation to see how almost constant measuring and assessing leads to few concrete learning gains. 

As a disconnected, automated, and isolated practice, digital assessment is the worst of what technology has to offer us. Quizzes and tests can be given through the course management system of your choice, offering students immediate feedback and weary instructors less to grade. Faculty can track how often their students log into the system, how long they spend on particular course units, and how many times they view particular topics. But these are anemic assessments at best, providing only the most rudimentary information about access and usage, not knowledge production and learning. The central question here is what have students actually learned. It measures exactly two things: usage (how often students have accessed material) and memorization.  

The worst of technology and assessment speaks to a lack of process; little about the kinds of assessment described above engage with the transformative potential  of digital technology and the cultural shifts in the last 15 years that have afforded us these possibilities. Instead, these assessment techniques reproduce the poorest paradigms for education. Stripped of any focus on knowledge production or engagement, this assessment approach enabled by technology is an automated banking system, where students regurgitate learned information that can be processed quickly and efficiently into a tidy metric. It supports industrial notions of education getting ever faster, ever shallower. 

The flip side of the new learning ecosystem are the cultural and pedagogical transformations in classrooms where pedagogues are reshaping, experimenting, and changing their approaches to teaching. So too, are they transforming our notions of assessment. Cathy N. Davidson's discussion of grading in *Now You See It* is a particularly useful starting point. Reflecting on her controversial experiment with crowd-sourced grading, she writes, "in the end, all assessment is circular: It measures what you want it to measure by a standard of excellence that you determine in advance. We too often substitute test results for some basic truth about a whole person, partly because we live in a test-obsessed society giving more tests (and at a younger age) than any other country" (118-199). In "12 Steps for Creating a Digital Assignment or Hybrid Class," Jesse Stommel asks key questions, such as, "Does this activity need to be assessed?"; "Can my assessment arise organically from within, and as part of, the learning activity?"; and, most important, "What is my goal in assessing student work?" (n. pag.). Stommel believes, as do I, that teaching is "a recursive process, a constant interplay between building and analyzing what we've built" (n. pag.). Asked by pedagogues who are interested in how students make meaning of course material, these questions stem from an interactive classroom and learning environment that help students to engage subject matter deeply and critically. They seek to ensure that what is being measured in the classroom is what needs to be measured and will ultimately help to shape and guide a student's learning process. They are also willing to challenge traditional notions of  the professor's role in the classroom and how that ultimately affects assessment.

In 2005, Madeleine Sorapure wrote, "Examining how student work in new media is currently assessed, it is clear that we are at a transitional stage in the process of incorporating new media into our composition courses. As [Kathleen Blake] Yancey notes, we give multimodal assignments but often draw on what we are far more familiar with--that is, print--to assess student work" (n. pag.). We are assigning the work, but as Cathy N. Davidson explores, we have not yet aligned our assessments with what we are asking students to do. Right now, many faculty still struggle to assess multimodal student work that comes in forms as varied as traditional essays to websites to games to videos to presentations to in-depth experiences such as service learning and travel. This is a process, one that should engage both faculty and students together, shaping our emerging understanding of the new learning ecosystem. 

Progressive digital assessments can take many forms, from games to badges to e-portfolios to multimodal projects in both course projects and as large-scale institutional practices. For example, an institution might measure student learning for accreditation through an e-portfolio and a classroom professor might ask students to keep a course portfolio of work during the semester. Students might add badges to a resume to show the particular skills they learned in a course or set of courses. Digital assessment coupled with digitally enriched curriculum takes risks by finding new ways to teach with new tools that require new assessment measures. Game-based learning, for example, introduces a non-punitive, recursive element to the curriculum, ensuring that students have the opportunity to learn through repeated attempts in engaged, interactive learning. 

When I think about assessment at its best and the current limitations of digital assessment, I think about my Fitbit. I love seeing my real time statistics during the day: heart rate, steps, calories burned. I love syncing that information to the app on my phone where I can further chart long-term trends and places where I can improve. Yet the Fitbit itself is limited. At the end of the day, numbers are just numbers. I wonder what Frank Gilbreth, who famously strove to make his family more and more efficient in *Cheaper by the Dozen*, would make of our consumption of data. My Fitbit's usefulness is limited for two reasons. First, more effective would be a coach who reviewed the data with me and made targeted suggestions about nutrition and exercise to help me improve. I need the ability to understand and act on what that data is telling me. Second, I am receiving data and analytics that have been preselected for me. I have not had any input in the kind of data I am receiving to make it even more useful for my targeted goals. 

This is still the possibility of learning analytics, still in their infancy: a world where students can use assessment information on the go to shape and direct their learning in collaboration with faculty who guide student progress. It is also a world where, ideally, students and faculty would co-create the metrics and standards by which a student is being assessed instead of plugging into a fabricated ecosystem where those parameters are predetermined and not necessarily useful. 

At its best, digital assessment offers us new ways to understand what our students our learning. In the humanities, our courses are rarely about a single subject. Sure, a student may have signed up for Spanish 101 to learn the language, but implicit in that journey is a wealth of information about culture, history, politics, and more. In literature classes, students go far beyond the word on the page. A text opens up worlds for interpretation and analysis. A simple quiz or test cannot adequately capture all of that learning. Good assessment design has always been predicated on multiple measures. 

This is where assessment in digital pedagogy excels. Digitally-based assessments allow faculty and students to work together to develop modes of expressing what students have learned that graciously accommodate widely varied content, form, and function. Often, these assessments are more personal than standardized tests or exams; they often privilege collaboration and showcase new ways of working together. These assessments model the way students work and, as important, the way they will be asked to work when they leave the praxis of the classroom. Digital assessments also often include a self-reflective element where students have the opportunity to shape and analyze their own learning. 

That said, however, our notions of what to assess and how to assess are emerging at best. In 2009, David Scobey's "Meaning and Metrics" isolated the problem as he retold the story of evaluating the meaning of the humanities from the perspective of a student studying racial identity and politics who transfers. Scobey asks, "How do we assess this student's learning? I mean this in both senses: how successful was his experience, and what tools would we use to measure that success? Should the downward blip on his college's retention rate, or the low marks that he might have given on a NSSE-style survey, be assessed as tokens of failure?" (n. pag.). You should read Scobey's elegant piece. But for the purposes of this reflection, I'll tell you that the student whose education Scobey explores is Barack Obama. It's the perfect example of how limited our current metrics are and how little we actually understand about what a student learns, how learning is truly longitudinal and integrative in nature, far beyond the classroom, the residence hall, the work or internship experience. Digital assessment is a step in helping students, faculty, and institutions begin to grapple with the "gestalt" of student learning: how we talk about student learning in its many complexities and contexts and progressions. 

For those readers who have taught with a paper portfolio system, this might sound all too familiar. The roots of digital assessment are anchored in history. What becomes different, then, is both the mode and style of working. Digital assessment design also allows for a greater transparency; instead of the transactional relationship between faculty member and student, work is now crafted for a wider discourse community. Work is often a public product published digitally--on a website or an app--allowing knowledge from the classroom to flow back into the college and local communities. What students learn has a different weight than an assignment produced in isolation. Their knowledge is not only transparent, but also interactive: they learn by doing and also by engaging others. Knowledge becomes again a communal practice. Now, assessment can ask not just what a student learned and how but also what impact that learning had on a local community. Part of the educational process: learning, producing, and assessing is also about how to navigate the digital world. Part of our work as faculty is to help students understand the vulnerabilities and the risks in public work. 

Digital assessment also encourages, if not privileges, integration and connections. The transparency of digital assessment galvanizes the portability of skills and concepts from one course to another. Students can document and reflect on their academic trajectory across courses finding connections that faculty may not expect. For example, the English major who takes a required General Education course in Environmental Biology might find connections between science courses and a love of eco-writing. Those connections are fostered by the portability of digital tools that allow students to "carry" work from one course to another. Carefully designed reflective assignments also prompt students to make those connections at milestone points in the curriculum. Students' longitudinal learning and integration, instead of being a happy accident, is carefully connected through and across courses and co-curricular experiences. This, however, calls for a redistribution of responsibilities among faculty and departments, understanding a student's education as a shared responsibility. 

Research is at the heart of all scholarly work, including teaching. Assessment is simply an intellectual and scholarly investigation into the questions: what are your students learning, and how do you know? How do you create the best assessment measures for the kinds of assignments you want students to create? Digital assessment methods open up many new possibilities for the classroom, the student, and the teacher-researcher. In the artifacts below, you'll see how digital assignments and digital assessments work together. I like to think of effective and useful assessment design in the same way I think of composing poems: the final product is an organic, symbiotic combination of form and function born of a process. This is a snapshot of our current moment and how the digital has already reshaped education and will continue to help us find new ways to help students share what they are learning. 

## CURATED ARTIFACTS 

### Changing the Paradigm for Higher Education: Pedagogy and Assessment
![screenshot](images/assessmentHASTAC.png)

* Source: [https://www.hastac.org/collections/hastac-guide-future-higher-education-chapter-5](https://www.hastac.org/collections/hastac-guide-future-higher-education-chapter-5)
* Copy of Artifact: forthcoming
* Creators: HASTAC, Collaborative Authors 

HASTAC has played a central role in documenting changing notions of pedagogy and a 21st-century classroom. This collection of practices considers assessment from the following perspectives: makerspaces, creative contributions, student leadership, diversity, digital badging, aligning assessments with pedagogy, and focusing on learning and mastery rather than testing. 

JENTERY: Great to see HASTAC, and this project in particular, included among your curated artifacts. Would you be willing to elaborate on the annotation, either pointing readers to specific aspects of this collection or mentioning what from it you've used in your own teaching practices? 

### Introduction to Digital Humanities Syllabus
![screenshot](images/assessmentGraham.png)

* Source: [http://dhcu.ca/pages/syllabus](http://dhcu.ca/pages/syllabus)
* Copy of Artifact: forthcoming
* Creator: Shawn Graham

This syllabus is a prime example of structuring digital content with multiple digital assessments. The presentation of the course models the kind of work students will be doing, from a video introduction to the use of digital tools, such as Slack, Github, and Pecha Kucha presentations. Significantly, Graham also addresses the importance of "public-facing" work, articulating a central shift in student work. Here, the public nature of student work is central to both the course design and course outcomes. 

JENTERY: I find this syllabus very compelling, too. Would you be willing to add a sentence or two about how exactly public work is assessed in this course? Not just that it's central, but how it's valued or graded? 

### "Introduction to Narrative": A Collaborative, Experimental Intellectual Adventure
![screenshot](images/assessmentSavonic.png)

* Source: [https://www.hastac.org/blogs/danicasavonick/2015/05/18/introduction-narrative-collaborative-experimental-intellectual](https://www.hastac.org/blogs/danicasavonick/2015/05/18/introduction-narrative-collaborative-experimental-intellectual)
* Copy of Artifact: forthcoming 
* Creator: Danica Savonick

This syllabus on narrative begins with a very clear relationship between the content of the course, the mode of work production, and assessment. The course engaged students in collaborative projects including crowd-sourced class notes using SoundCloud, public writing in blogs, and collaborative final projects. You can view student examples and reflections on the original source, demonstrating both how students are engaging in highly sophisticated multimodal projects and critique with student-designed evaluations. This syllabus demonstrates several key aspects of the changing nature of assessment: collaborative projects, student leadership in their own assessment and evaluation, and the critical importance of public writing and public work in digital scholarship for both faculty and students. 

JENTERY: Another compelling example. Thanks! Here again, would you be willing to add a sentence or two about how exactly work is assessed in this course?

### Evaluating Digital Humanities Projects: Collaborative Course Assessment
![screenshot](images/assessmentGould.png)

* Source: [http://sites.duke.edu/lit80s_01_f2014/evaluating-digital-humanities-projects-collaborative-course-assessment/](http://sites.duke.edu/lit80s_01_f2014/evaluating-digital-humanities-projects-collaborative-course-assessment/)
* Copy of Artifact: forthcoming 
* Creator: Amanda Starling Gould

This assignment includes multiple measures, collaboration, integration of concepts outside of the classroom, and modeling professional expectations for students in the discipline. Students are not only evaluating digital humanities projects; they are also using digital markup tools to learn how to collaboratively evaluate and respond to digital work. This is a key example of learning by doing: the form and content of the assignment and the assessment work together seamlessly.  

JENTERY: Great to see Gould's work in your list, too. Here, I'll just echo some of my remarks on other artifacts. Would you be willing to address not only the interesting projects students are doing in these classes but also how they are being assessed? Is there a way to point readers to specific assessment techniques, and then underscore why these techniques are persuasive or appropriate for the project at hand? 

### La Mentira
![screenshot](images/assessmentLaMentira.jpg)

* Source: [http://www.mentira.org/](http://www.mentira.org)
* Copy of Artifact: forthcoming
* Creators: Chris Holden and Julie Sykes, University of New Mexico, Lead Designers; Linda Lemus, Aaron Salinger, Derek Roff, University of New Mexico, Game Designers

The creators of La Mentira explain, "The backbone of this project is a focus on a natural context, outside the classroom, for the study of Spanish, and the development of materials for use in that context. We chose the Los Griegos neighborhood in Albuquerque/Los Ranchos for its connection to the Spanish language, documented history, diverse use and architecture, and walkability. We used information collected from neighborhood contacts, documentary archives, and a thesis written about the area, as well as multiple site visits from which to build the story and setting for our game." This game offers students a vehicle for practicing language acquisition skills, history, and culture in an interactive digital environment.

JENTERY: This is also great. Thank you for including an artifact anchored in the study of Spanish. Would you be willing to elaborate on its assessment techniques? I also wonder if, for the sake of annotation, the quotation could be either reduced (in length) or paraphrased. That is, it would be great to get more of your perspective here.  

### Notre Dame E2B2 Badge
![screenshot](images/assessmentND.png)

* Source: [http://eportfolio.nd.edu/directory/badge-directory/](http://eportfolio.nd.edu/directory/badge-directory/)
* Copy of Artifact: forthcoming 
* Creator: Alex Ambrose

The badging project at Notre Dame explores new ways of making learning transparent by quickly identifying the transferable skills connected with each course or co-curricular experience. Badges have a practical application and serve to document student learning in classroom and co-curricular settings. 

JENTERY: I'm glad to see this entry addressing badges, which have also been criticized (for gamification, e.g.). Would you be willing to address such concerns? Also, echoing remarks above, would you be willing to speak more specifically to badges as assessment techniques? Thanks, Liz! 

### Reflection from Emblematica Online
![screenshot](images/assessmentHeim.png)

* Source: [https://emblematicaonlineuiuc.wordpress.com/heidi-heim/](https://emblematicaonlineuiuc.wordpress.com/heidi-heim/)
* Copy of Artifact: forthcoming 
* Creator: Heidi Heim

Heim is one of several Emblem Scholars at the University of Illinois at Urbana-Champaign who engaged in undergraduate digital humanities research. Student researchers "create metadata by transcribing emblem mottos and associating this data with their respective emblems in their book for scholarly and pedagogical purposes. This digital humanities project focuses on Renaissance Emblem books." Heim's personal narrative provides a self-assessment of key skills and concepts learned in the context of this collaborative research project. Further, this project is a prime example of modeling professional expectations for students as Heim and her Emblem Scholars cohort worked alongside faculty as participatory researchers. 

JENTERY: Wonderful to see undergraduate research included here. Would you be willing to elaborate on how this participatory research was assessed? 

### Structuring Reflection
![screenshot](images/assessmentLuther.png)

* Source: [https://www.hastac.org/blogs/taxomania/2014/01/28/02-using-zines-classroom](https://www.hastac.org/blogs/taxomania/2014/01/28/02-using-zines-classroom)
* Copy of Artifact: forthcoming 
* Creator: Jason Luther

The previous student example of reflection demonstrates how a student might approach narratively describing the skills and concepts learned in connection with a particular project, assignment, course, or series of courses. A key question in reflective assignments is how you get students to reflect meaningfully. Luther's assignment shows the careful use of guiding questions that allow students to consider what they produced (a zine), what they learned, and how they self-assess their learning.

JENTERY: I especially appreciate the last sentence of this annotation. Would you be willing to elaborate on it? How does self-assessment happen, and how is it prompted? 

### Catalyst for Learning ePortfolio Site
![screenshot](images/assessmentCatalyst.png)

* Source: [http://c2l.mcnrc.org/oa/](http://c2l.mcnrc.org/oa/)
* Copy of Artifact: forthcoming 
* Creators: Bret Eynon, Laura Gambino, Randy Bass, Helen Chen, principal investigators and C2L Campus Teams

The Catalyst for Learning site is an extensive resource for learning more about e-portfolios structured in several ways: thematically, via campus stories, and through the lens of a principal investigator. The site provides multiple views of e-portfolios on campuses across the country. The result of a three-year research project, key campuses using e-portfolios studied their own practices and documented them on the site. The principal investigators then studied that work and wrote analyses of each theme. One of those themes is assessment. By following through the assessment portion of the site, e-portfolios demonstrate a rich potential to provide authentic assessment of longitudinal student learning. 

JENTERY: Thanks for this, Liz! Would you be willing to elaborate on how longitudinal student learning is assessed via e-portfolios? Have you used Catalyst for Learning in your own work? If so, then would you be willing to speak to its use for assessment? 

### Holding for Darryl Draper app project
IMAGE FORTHCOMING 

* Source: forthcoming
* Copy of Artifact: forthcoming 
* Creators: forthcoming 

ANNOTATION FORTHCOMING.

JENTERY: Looking forward to reading this one! 

## RELATED MATERIALS 

Bass, Randall and Bret Eynon. _Open and Integrative: Designing Liberal Education for the New Digital Ecosystem_. Washington, D.C.: Association of American Colleges and Universities, forthcoming. Web.

Ifenthaler, Dirk, Deniz Eseryel, and Xun Ge. _Assessment in Game-Based Learning_. New York: Springer-Verlag, 2012. 

Losh, Elizabeth. _The War on Learning: Gaining Ground in the Digital University._  Cambridge, MA: The MIT Press, 2014. Print. 

McKee, Heidi A. and Danielle Nicole DeVoss, Eds. [Digital Writing: Assessment and Evaluation](http://ccdigitalpress.org/dwae/intro.html). Logan, UT: Computers and Composition Digital Press/Utah State University Press, 2013. Web. 

Richard-Schuster, Katie, Mary Ruffle, Kerri Leyda Nicoll, Catherine Distelrath, and Joseph Galura. ""[Using ePortfolios to Assess Program Goals, Integrative Learning and Civic Engagement: A Case Example](http://www.theijep.com/pdf/IJEP150.pdf)." _The International Journal of ePortfolio_ 4.2 (2014): 133-141. Web. 

## WORKS CITED 

Davidson, Cathy N. _Now You See It: How the Brain Science of Attention Will Transform the Way We Live, Work, and Learn_. New York: Viking, 2011. Print.

Eggers, Dave. _The Circle: A Novel_. New York: Alfred A. Knopf, 2013. Print.

Sorapure, Madeleine. "[Between Modes: Assessing Students' New Media Compositions](http://kairos.technorhetoric.net/10.2/binder2.html?coverweb/sorapure/index.html)." _Kairos_ 10:2 (2005). Web.

Stommel, Jesse. "12 Steps for Creating a Digital Assignment or Hybrid Class." [http://jessestommel.com/12-steps-for-creating-a-digital-assignment-or-hybrid-class](http://jessestommel.com/12-steps-for-creating-a-digital-assignment-or-hybrid-class)
